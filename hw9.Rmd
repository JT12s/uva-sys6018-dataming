---
title: "Homework #9: Association Analysis" 
author: "**Jie Tang**"
date: "Due: Tue May 3 | 10:30 am"
output: R6018::homework
---

**SYS 4582/6018 | Spring 2022 | University of Virginia **

*******************************************
```{r config, echo=FALSE}
source(system.file("config/hw_config.R", package="R6018")) # knitr settings
# options(dplyr.summarise.inform = FALSE)  # ignore dplyr message about grouping
```


# Required R packages and Directories

::: {.solution}
```{r packages, message=FALSE, warning=FALSE}
data.dir = 'https://mdporter.github.io/SYS6018/data/' # data directory
library(R6018)     # functions for DS-6018
library(arules)    # functions for Association Rules
library(tidyverse) # functions for data manipulation
# Add others if necessary
```
:::



# Problem 1: Interestingness 

Suppose we have market basket data consisting of 100 transactions and 20 items. Assume the support for item {$a$} is 20%, support for item {$b$} is 85%, and support for itemset {$a,b$} is 15%. 


## a. What is the confidence of the rule {a} $\rightarrow$ {b}? 

::: {.solution}
Support of {a} is 20% which means pr(a in T) = 20%
Support of {b} is 85% which means pr(b in T) = 85%
Support of {a,b} is 15% which means pr(a and b in T) = 15%
The confidence of a rule is:
– C(I → J) = S(I,J)/S(I) ˆ= Pr(I⊆T,J⊆T)/Pr(I⊆T) = P(J ⊆ T|I ⊆ T)
So C(a -> b ) = 0.15/0.20 = 0.75
:::


## b. Will the apriori algorithm find this rule (interesting) if the confidence threshold (minconf) is $c=.60$ and the support threshold (minsup) is $s=.10$?  

::: {.solution}
Yes. Both {a} and {b} are frequent (have support larger than .10). And the confidence of rule {a} -> {b} is 75% which is larger than minconf. 
:::


## c. Find the *lift* of this rule. 

::: {.solution}
Definition of lift is: L(I, J) = C(I → J)/S(J)
So L(a, b) = 0.75/0.85 = 0.8824

:::

## d. Find the *addedValue* of this rule. 

::: {.solution}
Definition of addedValue is AV(I → J) = C(I → J) − S(J)
So AV(a, b) = 0.75 - 0.8 = -0.05
:::


## e. Find the *leverage/PS* of this rule. 

::: {.solution}
Definition of leverage/PS is PS(I, J) = S(I, J) − S(I)S(J)
So PS(a ,b) = 0.15 - 0.2*0.85 = -0.02
:::


## f. Describe the nature of the relationship between items {a} and {b} according to *lift*, *addedValue* and *leverage/PS*. What observation can you draw from parts (b) and (c-e)? 

::: {.solution}
Lift result we calculated above is 0.8824 which is smaller than 1. Based on the definition of lift, we consider that items {a} and {b} have negative association. It means that {a} and {b} inhibit each other and they are not expected appear at same basket. 
The addedValue result is -0.05. And this result is showing difference between conditional and unconditional. P({b}|{a}) stands for the possibility of picking {b} when {a} already in basket and P({b}) stands for the possibility without {a} in it. So, -0.05 means that they seems more likely show up separately.
The PS result is -0.02, and it is showing difference of observed and expected. -0.02 also means they unlikely appear togther.
By apriori approach, we found the rule {a} -> {b} is interesting. But I think this is because {b} has a high support which cause that everything to {b} will be interesting based on apriori approach. From results in (c-e), they are actually saying that they have negative or nearly no association between each other because addedValue and PS results are almost 0.
:::

## g. Let $p(a)$, $p(b)$, and $p(a,b)$ be the actual probabilities of observing items {a}, {b}, and {a,b} respectively in a transaction. What is the expected confidence rule {a} $\rightarrow$ {b} if a and b are independent? 

::: {.solution}
If item {a} and {b} are independent, it means that p(a,b) = p(a)*p(b).
And confidence rule is calculated by C(I → J) = S(I,J)/S(I) = Pr(I⊆T,J⊆T)/Pr(I⊆T). It would be p(a,b)/p(a) = p(a)p(b)/p(a) = p(b).
It is the probabilities of itms {b} if they are independent. It makes sense because if they have no relation between each other, prob of b that a alread in basket will be equal to prob of b with nothing in basket.
:::



# Problem 2: Online Retail

The website <http://archive.ics.uci.edu/ml/datasets/online+retail> describes some transactional data from an online retailer. 


## a. Download the [excel file](http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx) to your machine and read it into R. 
- Loading Excel data: `readxl::read_excel()` (part of tidyverse)


::: {.solution}
```{r}
data = readxl::read_excel('Online Retail.xlsx')
```

:::


## b. There are many quality problems with this dataset, but we will only address two of them. Remove all of the rows with missing Description values (NAs) and remove any duplicate items in a single transaction. Print the first 10 rows of the resulting data. 

::: {.solution}
```{r}
#check whether there is NAs in Description values
any(is.na(data$Description))
print("Original data length")
print(length(data$Description))
#drop NAs 
data <- data[!is.na(data$Description),]
print("After drop NAs")
print(length(data$Description))
data <- data %>% distinct(InvoiceNo, StockCode, .keep_all = TRUE)
print("After removing duplicated")
print(length(data$Description))
head(data, 10)
```

:::

## c. Find the number of transactions and number of items using *InvoiceNo* for transactions and *Description* as items (i.e., ignore the *StockCode* column).

::: {.solution}
```{r}
NT = n_distinct(data$InvoiceNo)     # Number of transactions
NI = n_distinct(data$Description) # Number of items
print(NT)
print(NI)
```

:::


## d. Convert the data frame into a *transaction list* and convert it into a *transactions object* (don't forget to load the `arules` package). Print a summary (using `summary()`) of the new object. 

::: {.solution}
```{r}
#-- get transaction list
tList = split(data$Description, data$InvoiceNo)    # get transaction list
# tList = lapply(tList, unique)              # another way to remove duplicates  

#-- get transaction class
library(arules)
trans = as(tList, "transactions")
summary(trans)
```

:::

## e. Find the items with the highest support. Print and plot the support of the top 10. 

::: {.solution}
```{r}
#-- get item counts and support for single itemsets
itemFreq = count(data, Description, sort=TRUE) %>% mutate(support=n/NT)


# plot top 10
itemFreq %>% slice(1:10) %>% 
  ggplot(aes(fct_reorder(Description, n), n)) + # order bars by n
  geom_col() +         # barplot
  coord_flip() +       # rotate plot 90 deg
  theme(axis.title.y = element_blank()) # remove y axis title

```

:::

## f. Find the *frequent itemsets* that contain at least 3 items and have $s\geq 0.02$. Add the *lift* metric. Show all results, ordered by *lift*. 

::: {.solution}
```{r}
#-- Find all frequent itemsets (s=.02) of length 3 (minlen=3)
fis2 = apriori(trans, 
               parameter = list(support = .02, minlen=3, target="frequent"))

apriori2df(fis2) %>% arrange(-support)  # order by support (largest to smallest)
#-- Add lift using the interestMeasure() function
apriori2df(fis2) %>% 
  mutate(lift = interestMeasure(fis2, measure="lift", trans)) %>% 
  arrange(-lift)
```

:::

## g. Find all of the *association rules* with $s \geq 0.02$, $c \geq 0.70$. Add the *PS/leverage* and *addedValue* metrics. Show all results, ordered by *addedValue*

::: {.solution}
```{r}
#-- Find association rules with support>=.02 and confidence>=.70
rules = apriori(trans, 
             parameter = list(support=.02, confidence=.70, 
                              minlen=2,target="rules"))

apriori2df(rules) %>% arrange(-confidence)  # order by confidence metric
apriori2df(rules) %>% arrange(-lift)        # order by lift metric


#-- Add other interest measures
apriori2df(rules) %>% 
  mutate(addedValue = interestMeasure(rules, measure="addedValue", trans), 
         PS = interestMeasure(rules, measure="leverage", trans)) %>% 
  arrange(-addedValue)
```

:::


## h. Find one rule that you think is interesting. Write the rule and explain why you find it interesting. 

::: {.solution}
The itemset that has the highest lift is {GREEN REGENCY TEACUP AND SAUCER,PINK REGENCY TEACUP AND SAUCER}. This itemset also has a pretty high rank in other measurements.
So the rule is {GREEN REGENCY TEACUP AND SAUCER} -> {PINK REGENCY TEACUP AND SAUCER}. It is interesting that people would tend to have different color for a same item. It also has a high support. So teacup is really an important thing in British.
:::

